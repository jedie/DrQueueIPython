# -*- coding: utf-8 -*-

"""
Console management program for DrQueue.
Copyright (C) 2012-2013 Andreas Schr√∂der

This file is part of DrQueue.

Licensed under GNU General Public License version 3. See LICENSE for details.
"""

import string
import argparse
import getpass
import DrQueue
from DrQueue import Job as DrQueueJob
from DrQueue import Client as DrQueueClient

import os, signal, subprocess, sys, platform, time, socket, datetime
from collections import deque
import pkg_resources


SIGTERM_SENT = False
SIGINT_SENT = False
MONGODB_PID = None
IPCONTROLLER_PID = None
IPENGINE_PID = None



# 
# drqueue job list (list_jobs.py)
# drqueue job add (send_job.py)
# drqueue job delete job_name|job_id (control_job.py)
# drqueue job requeue job_name|job_id (control_job.py)
# 
# drqueue computer list (list_computers.py)
# drqueue computer restart computer_name|conputer_id (control_computer.py)
# drqueue computer pool computer_name|conputer_id pool_name (control_computer.py)
#
# drqueue security lock (drqueue_security)
# drqueue security unlock (drqueue_security)
# 

args_dict = None

def main():
    global args_dict

    # create parent parser for global options
    parent_parser = argparse.ArgumentParser(add_help=False)
    parent_parser.add_argument("-v", "--verbose", action="store_true", dest="verbose", default=False, help="verbose output")

    # create the top-level parser
    parser = argparse.ArgumentParser(parents=[parent_parser])
    subparsers = parser.add_subparsers(title="subcommands")


    # create the parser for the job command
    parser_job = subparsers.add_parser("job", help="job management", parents=[parent_parser])

    # create the parsers for job subcommands and set their handler functions
    subparsers_job = parser_job.add_subparsers(title="subcommands")
    parser_job_list = subparsers_job.add_parser("list", help="list one or more jobs", parents=[parent_parser])
    parser_job_list.set_defaults(func=job_list)
    parser_job_add = subparsers_job.add_parser("add", help="add a new job", parents=[parent_parser])
    parser_job_add.set_defaults(func=job_add)
    parser_job_stop = subparsers_job.add_parser("stop", help="stop running job", parents=[parent_parser])
    parser_job_stop.set_defaults(func=job_stop)
    parser_job_kill = subparsers_job.add_parser("kill", help="kill running job", parents=[parent_parser])
    parser_job_kill.set_defaults(func=job_kill)
    parser_job_delete = subparsers_job.add_parser("delete", help="delete existing job", parents=[parent_parser])
    parser_job_delete.set_defaults(func=job_delete)
    parser_job_continue = subparsers_job.add_parser("continue", help="continue stopped job", parents=[parent_parser])
    parser_job_continue.set_defaults(func=job_continue)
    parser_job_rerun = subparsers_job.add_parser("rerun", help="rerun stopped job", parents=[parent_parser])
    parser_job_rerun.set_defaults(func=job_rerun)

    # options for job list action
    parser_job_list.add_argument("-i", "--id", dest="id", help="job id")
    parser_job_list.add_argument("-n", "--name", dest="name", help="job name")
    parser_job_list.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all jobs")

    # options for job add action
    parser_job_add.add_argument("-s", "--startframe", dest="startframe", default=1, help="first frame")
    parser_job_add.add_argument("-e", "--endframe", dest="endframe", default=1, help="last frame")
    parser_job_add.add_argument("-b", "--blocksize", dest="blocksize", default=1, help="size of block")
    parser_job_add.add_argument("-n", "--name", dest="name", default=None, help="name of job")
    parser_job_add.add_argument("-r", "--renderer", dest="renderer", help="render type (maya|blender|mentalray)")
    parser_job_add.add_argument("-f", "--scenefile", dest="scenefile", default=None, help="path to scenefile")
    parser_job_add.add_argument("-p", "--pool", dest="pool", default=None, help="pool of computers")
    parser_job_add.add_argument("-o", "--options", dest="options", default="{}", help="specific options for renderer as Python dict")
    parser_job_add.add_argument("--retries", dest="retries", default=1, help="number of retries for every task")
    parser_job_add.add_argument("--owner", dest="owner", default=getpass.getuser(), help="Owner of job. Default is current username.")
    parser_job_add.add_argument("--os", dest="os", default=None, help="Operating system")
    parser_job_add.add_argument("--minram", dest="minram", default=0, help="Minimal RAM in GB")
    parser_job_add.add_argument("--mincores", dest="mincores", default=0, help="Minimal CPU cores")
    parser_job_add.add_argument("--send-email", action="store_true", dest="send_email", default=False, help="Send notification email when job is finished")
    parser_job_add.add_argument("--email-recipients", dest="email_recipients", default=None, help="Recipients for notification email")
    parser_job_add.add_argument("-w", "--wait", action="store_true", dest="wait", default=False, help="wait for job to finish")
    parser_job_add.set_defaults(func=job_add)

    # options for job stop action
    parser_job_stop.add_argument("-i", "--id", dest="id", help="job id")
    parser_job_stop.add_argument("-n", "--name", dest="name", help="job name")
    parser_job_stop.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all jobs")

    # options for job kill action
    parser_job_kill.add_argument("-i", "--id", dest="id", help="job id")
    parser_job_kill.add_argument("-n", "--name", dest="name", help="job name")
    parser_job_kill.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all jobs")

    # options for job delete action
    parser_job_delete.add_argument("-i", "--id", dest="id", help="job id")
    parser_job_delete.add_argument("-n", "--name", dest="name", help="job name")
    parser_job_delete.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all jobs")

    # options for job continue action
    parser_job_continue.add_argument("-i", "--id", dest="id", help="job id")
    parser_job_continue.add_argument("-n", "--name", dest="name", help="job name")
    parser_job_continue.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all jobs")

    # options for job rerun action
    parser_job_rerun.add_argument("-i", "--id", dest="id", help="job id")
    parser_job_rerun.add_argument("-n", "--name", dest="name", help="job name")
    parser_job_rerun.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all jobs")


    # create the parser for the computer command
    parser_computer = subparsers.add_parser("computer", help="computer management", parents=[parent_parser])

    # create the parsers for computer subcommands and set their handler functions
    subparsers_computer = parser_computer.add_subparsers(title="subcommands")
    parser_computer_list = subparsers_computer.add_parser("list", help="list known computers", parents=[parent_parser])
    parser_computer_list.set_defaults(func=computer_list)
    parser_computer_restart = subparsers_computer.add_parser("restart", help="restart computer", parents=[parent_parser])
    parser_computer_restart.set_defaults(func=computer_restart)
    parser_computer_pool = subparsers_computer.add_parser("pool", help="set pool membership of computers", parents=[parent_parser])
    parser_computer_pool.set_defaults(func=computer_pool)

    # options for computer list action
    parser_computer_list.add_argument("-i", "--id", dest="id", help="computer id")
    parser_computer_list.add_argument("-n", "--name", dest="name", help="computer name")
    parser_computer_list.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all computers")

    # options for computer restart action
    parser_computer_restart.add_argument("-i", "--id", dest="id", help="computer id")
    parser_computer_restart.add_argument("-n", "--name", dest="name", help="computer name")
    parser_computer_restart.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all computers")

    # options for computer pool action
    parser_computer_pool.add_argument("-i", "--id", dest="id", help="computer id")
    parser_computer_pool.add_argument("-n", "--name", dest="name", help="computer name")
    parser_computer_pool.add_argument("-p", "--pools", dest="pools", help="list of pools")
    parser_computer_pool.add_argument("-a", "--all ", action="store_true", dest="all", default=False, help="use all computers")

    
    # create the parser for the security command
    parser_security = subparsers.add_parser("security", help="toggle IPython security folder permissions", parents=[parent_parser])
    parser_security.add_argument("security_action", help="lock / unlock")


    # create the parser for the master command
    parser_master = subparsers.add_parser("master", help="start in master daemon", parents=[parent_parser])
    parser_master.set_defaults(func=master_daemon)


    # create the parser for the slave command
    parser_slave = subparsers.add_parser("slave", help="start in slave daemon", parents=[parent_parser])
    parser_slave.set_defaults(func=slave_daemon)


    # parse arguments
    args = parser.parse_args()

    # debug parsed arguments
    print args

    # execute function bound to chosen subparser
    args.func(args)


    # if ("job_action" in args_dict):
    #     # drqueue job list
    #     if args_dict["job_action"] == "list":
    #         print "user chose list action"
    #         if ("id" in args_dict) and (args_dict["id"] != None):
    #             list_jobs(args_dict["id"], None)
    #         elif ("name" in args_dict) and (args_dict["name"] != None):
    #             list_jobs(None, args_dict["name"])
    #         else:
    #             list_jobs()
    #     # drqueue job add
    #     elif args_dict["job_action"] == "add":
    #         print "user chose add action"
    #         add_job()
    #     # drqueue job stop job_name|job_id
    #     elif args_dict["job_action"] == "stop":
    #         print "user chose stop action"
    #     # drqueue job kill job_name|job_id
    #     elif args_dict["job_action"] == "kill":
    #         print "user chose kill action"
    #     # drqueue job delete job_name|job_id
    #     elif args_dict["job_action"] == "delete":
    #         print "user chose delete action"
    #     # drqueue job continue job_name|job_id
    #     elif args_dict["job_action"] == "continue":
    #         print "user chose continue action"
    #     # drqueue job rerun job_name|job_id
    #     elif args_dict["job_action"] == "rerun":
    #         print "user chose rerun action"
    #     else:
    #         print("Error: Unknown parameter specified.")
    #         exit(1)
    
    # if ("computer_action" in args_dict):
    #     cache_time = 60
    #     # drqueue computer list
    #     if args_dict["computer_action"] == "list":
    #         print "user chose list action"
    #     # drqueue computer restart computer_name|conputer_id
    #     elif args_dict["computer_action"] == "restart":
    #         print "user chose restart action"
    #     # drqueue computer pool computer_name|conputer_id pool_name
    #     elif args_dict["computer_action"] == "pool":
    #         print "user chose pool action"
    #     else:
    #         print("Error: Unknown parameter specified.")
    #         exit(1)


def job_list(args):
    # initialize DrQueue client
    client = DrQueueClient()

    print "user chose list action"

    job_id = args.id
    job_name = args.name

    if (job_id != None) and (job_name == None):
        # fetch information about single job
        jobs = [client.query_job_by_id(job_id)]
    elif (job_id == None) and (job_name != None):
        # fetch information about single job
        jobs = [client.query_job_by_name(job_name)]
    else:
        # fetch a list of all jobs
        jobs = client.query_job_list()
        
    # walk through tasks of every job
    for job in jobs:
        tasks = client.query_task_list(job['_id'])
        meantime, time_left, finish_time = client.job_estimated_finish_time(job['_id'])
        frame = job['startframe']
        
        print("\nJob \"%s\" (ID: %s):" % (job['name'], job['_id']))
        print("Overall status: " + client.job_status(job['_id']))
        print("Enabled: %s" % job['enabled'])
        print("Submit time: " + str(job['submit_time']))
        if job['requeue_time'] != False:
            print("Requeue time: "+ str(job['requeue_time']))
        print("Time per task: " + str(meantime))
        if client.query_job_tasks_left(job['_id']) > 0:
            print("Time left: " + str(time_left))
            print("Estimated finish time: " + str(finish_time))
        else:
            print("Finish time: " + str(finish_time))
        if 'pool_name' in job['limits']:
        	print("Pool: " + str(job['limits']['pool_name']))
        else:
        	print("Pool: Not set.")
        print("Task id\t\t\t\t\tframe\tstatus\towner\tcompleted at")
        
        for task in tasks:
            tmsg_id = task['msg_id']
            theader = task['header']
            username = theader['username']
        
            if task['completed'] == None:
                status = "pending"
                print("%s\t%i\t%s\t%s" % (tmsg_id, frame, status, username))
            else:
                result_header = task['result_header']
                result_content = task['result_content']
                status = result_header['status']
                cpl = task['completed']
                print("%s\t%i\t%s\t%s\t%i-%02i-%02i %02i:%02i:%02i" % (tmsg_id, frame, status, username, cpl.year, cpl.month, cpl.day, cpl.hour, cpl.minute, cpl.second))

                if result_header['status'] == 'error':
                	print("  Error was: " + result_content['evalue'])
            if int(job['blocksize']) > 1:
            	frame += int(job['blocksize'])
            else:
            	frame += 1

            # for debugging:
            #print(task)


def job_add(args):
    # initialize DrQueue client
    client = DrQueueClient()

    # set limits
    limits = dict()
    limits['pool_name'] = args_dict["pool"]
    limits['os'] = args_dict["os"]
    limits['minram'] = int(args_dict["minram"])
    limits['mincores'] = int(args_dict["mincores"])

    options_var = eval(args_dict["options"])
    options_var['send_email'] = args_dict["send_email"]
    options_var['email_recipients'] = args_dict["email_recipients"]

    # add standard Blender option
    if (args_dict["renderer"] == "blender") and ("rendertype" not in options_var):
        options_var['rendertype'] = "animation"

    # initialize DrQueue job
    job = DrQueueJob(args_dict["name"], int(args_dict["startframe"]), int(args_dict["endframe"]), int(args_dict["blocksize"]), args_dict["renderer"], args_dict["scenefile"], args_dict["retries"], args_dict["owner"], options_var, "send_job.py", limits)

    # run job with client
    try:
        client.job_run(job)
    except ValueError:
        print("One of your the specified values produced an error:")
        raise
        exit(1)

    # tasks which have been created
    tasks = client.query_task_list(job['_id'])

    # wait for all tasks of job to finish
    if args_dict["wait"]:
        if (tasks == []) and (client.query_computer_list() == []):
            print("Tasks have been sent but no render node is running at the moment.")
            exit(0)

        for task in tasks:
            ar = client.task_wait(task['msg_id'])
            # add some verbose output
            if args_dict["verbose"]:
                cpl = ar.metadata.completed
                msg_id = ar.metadata.msg_id
                status = ar.status
                engine_id = ar.metadata.engine_id
                print("Task %s finished with status '%s' on engine %i at %i-%02i-%02i %02i:%02i:%02i." % (msg_id, status, engine_id, cpl.year, cpl.month, cpl.day, cpl.hour, cpl.minute, cpl.second))
                if ar.pyerr != None:
                    print(ar.pyerr)
        print("Job %s finished." % job['name'])


def job_stop(args):
    # initialize DrQueue client
    client = DrQueueClient()


def job_kill(args):
    # initialize DrQueue client
    client = DrQueueClient()


def job_delete(args):
    # initialize DrQueue client
    client = DrQueueClient()


def job_continue(args):
    # initialize DrQueue client
    client = DrQueueClient()


def job_rerun(args):
    # initialize DrQueue client
    client = DrQueueClient()


def computer_list(args):
    # initialize DrQueue client
    client = DrQueueClient()


def computer_restart(args):
    # initialize DrQueue client
    client = DrQueueClient()


def computer_pool(args):
    # initialize DrQueue client
    client = DrQueueClient()


def is_port_open(ip, port):
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    try:
        s.connect((ip, int(port)))
        s.shutdown(2)
        return True
    except:
        return False


def master_sig_handler(signum, frame):
    global MONGODB_PID
    global IPCONTROLLER_PID

    if signum == signal.SIGINT:
        sys.stderr.write("Received SIGINT. Shutting Down.\n")
        global SIGINT_SENT
        if not SIGINT_SENT:
            SIGINT_SENT = True
            if IPCONTROLLER_PID > 0:
                sys.stderr.write("Sending INT to IPython controller.\n")
                os.kill(IPCONTROLLER_PID, signal.SIGINT)
                os.waitpid(IPCONTROLLER_PID, 0)
            if MONGODB_PID > 0:
                sys.stderr.write("Sending INT to MongoDB.\n")
                os.kill(MONGODB_PID, signal.SIGINT)
                os.waitpid(MONGODB_PID, 0)

    if signum == signal.SIGTERM:
        sys.stderr.write("Received SIGTERM. Shutting Down.\n")
        global SIGTERM_SENT
        if not SIGTERM_SENT:
            SIGTERM_SENT = True
            if IPCONTROLLER_PID > 0:
                sys.stderr.write("Sending TERM to IPython controller.\n")
                os.kill(IPCONTROLLER_PID, signal.SIGTERM)
                os.waitpid(IPCONTROLLER_PID, 0)
            if MONGODB_PID > 0:
                sys.stderr.write("Sending TERM to MongoDB.\n")
                os.kill(MONGODB_PID, signal.SIGTERM)
                os.waitpid(MONGODB_PID, 0)

    sys.exit()


def slave_sig_handler(signum, frame):
    global IPENGINE_PID

    # handle SIGINT
    if signum == signal.SIGINT:
        sys.stderr.write("Received SIGINT. Shutting Down.\n")
        global SIGINT_SENT
        if not SIGINT_SENT:
            SIGINT_SENT = True
            if IPENGINE_PID > 0:
                sys.stderr.write("Sending INT to IPython engine.\n")
                os.kill(IPENGINE_PID, signal.SIGINT)
                os.waitpid(IPENGINE_PID, 0)

    # handle SIGTERM
    if signum == signal.SIGTERM:
        sys.stderr.write("Received SIGTERM. Shutting Down.\n")
        global SIGTERM_SENT
        if not SIGTERM_SENT:
            SIGTERM_SENT = True
            if IPENGINE_PID > 0:
                sys.stderr.write("Sending TERM to IPython engine.\n")
                os.kill(IPENGINE_PID, signal.SIGTERM)
                os.waitpid(IPENGINE_PID, 0)

    sys.exit()


def run_command(command, logfile):
    try:
        p = subprocess.Popen(command, shell=True, stdout=logfile, stderr=subprocess.STDOUT)
    except OSError as e:
        errno, strerror = e.args
        message = "OSError({0}) while executing command: {1}\n".format(errno, strerror)
        logfile.write(message)
        raise OSError(message)
        return False
    return p


def master_daemon(args):

    if "DRQUEUE_MASTER" in os.environ:
        master_ip = os.environ["DRQUEUE_MASTER"]
    else:
        master_ip = socket.gethostbyname(socket.getfqdn())

    signal.signal(signal.SIGTERM, master_sig_handler)
    signal.signal(signal.SIGINT, master_sig_handler)

    pid = os.getpid()
    print("Running DrQueue master on " + master_ip + " with PID " + str(pid) + ".")

    if "DRQUEUE_ROOT" not in os.environ:
        sys.stderr.write("DRQUEUE_ROOT environment variable is not set!\n")
        sys.exit(-1)

    if "IPYTHONDIR" not in os.environ:
        sys.stderr.write("IPYTHONDIR environment variable is not set!\n")
        sys.exit(-1)

    # start MongoDB daemon
    command = "mongod --dbpath $IPYTHONDIR/db --rest"
    mongodb_logpath = os.path.join(os.environ["DRQUEUE_ROOT"], "logs", "mongodb.log")
    mongodb_logfile = open(mongodb_logpath, "ab")
    mongodb_daemon = run_command(command, mongodb_logfile)
    global MONGODB_PID
    MONGODB_PID = mongodb_daemon.pid
    print("MongoDB started with PID " + str(mongodb_daemon.pid) + ". Logging to " + mongodb_logpath + ".")

    # wait until port 27017 of MongoDB is available
    mongodb_available = False
    while mongodb_available == False:
        mongodb_available = is_port_open("127.0.0.1", 27017)
        time.sleep(2)
        print("Waiting for MongoDB to start up . . . ")

    # start IPython controller
    command = "ipcontroller --url tcp://" + master_ip + ":10101 --mongodb"
    ipcontroller_logpath = os.path.join(os.environ["DRQUEUE_ROOT"], "logs", "ipcontroller.log")
    ipcontroller_logfile = open(ipcontroller_logpath, "ab")
    ipcontroller_daemon = run_command(command, ipcontroller_logfile)
    global IPCONTROLLER_PID
    IPCONTROLLER_PID = ipcontroller_daemon.pid
    print("IPython controller started with PID " + str(ipcontroller_daemon.pid) + ". Logging to " + ipcontroller_logpath + ".")

    # wait for any child to exit
    os.wait()


def slave_daemon(args):

    if "DRQUEUE_ROOT" not in os.environ:
        sys.stderr.write("DRQUEUE_ROOT environment variable is not set!\n")
        sys.exit(-1)

    if "IPYTHONDIR" not in os.environ:
        sys.stderr.write("IPYTHONDIR environment variable is not set!\n")
        sys.exit(-1)

    if "DRQUEUE_MASTER" not in os.environ:
        sys.stderr.write("DRQUEUE_MASTER environment variable is not set!\n")
        sys.exit(-1)
    else:
        master_ip = os.environ["DRQUEUE_MASTER"]

    if "DRQUEUE_SLAVE" in os.environ:
        slave_ip = os.environ["DRQUEUE_SLAVE"]
    else:
        slave_ip = socket.gethostbyname(socket.getfqdn())

    ipengine_logpath = os.path.join(os.environ["DRQUEUE_ROOT"], "logs", "ipengine_" + slave_ip + ".log")
    ipengine_logfile = open(ipengine_logpath, "ab")
    dist_egg = pkg_resources.get_distribution("DrQueueIPython")
    startup_script = dist_egg.get_resource_filename(__name__, "EGG-INFO/scripts/get_slave_information.py")

    # register signal handler for SIGINT & SIGTERM
    signal.signal(signal.SIGTERM, slave_sig_handler)
    signal.signal(signal.SIGINT, slave_sig_handler)

    pid = os.getpid()
    print("Running DrQueue slave on " + slave_ip + " with PID " + str(pid) + ".")
    print("Connecting to DrQueue master at " + master_ip + ".")

    # restart ipengine if it was shut down by IPython
    while True:
        # start IPython engine along with startup script
        command = "ipengine --url tcp://" + master_ip + ":10101 -s " + startup_script
        ipengine_daemon = run_command(command, ipengine_logfile)
        global IPENGINE_PID
        IPENGINE_PID = ipengine_daemon.pid
        print("IPython engine started with PID " + str(IPENGINE_PID) + ". Logging to " + ipengine_logpath + ".")

        # wait for process to exit
        os.waitpid(IPENGINE_PID, 0)

        print("IPython was shut down. Restarting ...")
        time.sleep(5)


if __name__ == "__main__":
    main()
